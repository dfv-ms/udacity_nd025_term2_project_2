# udacity_nd025_term2_project_2
Project 2 for Udacity Nanodegree Data Science


That's my 2nd project for Udacity's Nanodegree "Data Sciencte - Term 2".

## About the project

The project consists of three parts:
* Create an ETL-Pipeline for loading the raw data after processing it into a SQLite Database
* Load the processed data from the SQLite Database and run a Machine Learning Pipeline. Save the model.
* Load the model and present an interface for classification as web-app.

### About the data
There are 26,000+ messages which are classified into up to 36 categories.
The task was to predict the associated categories by the message.

## Directories
* data contains the csv-files
* jupyter-notebooks contains the jupyter notebooks used for data exploration and setting up the pipelines
* workplace contains the files containing the project itself

* app: The flask app
* data: The ETL-pipeline
* models: The ML-pipeline

## ETL-Pipeline

The script for running the ETL-Pipeline is called "workplace/data/process_data.py".
It takes several arguments:
  * a csv-file with the messages
  * a csv-file with the categories_names
  * the name of the sqlite file to be written

During data exploration I saw 200+ lines with unknown values (2 instead of 0 or 1)
for the category "related". So I dropped these rows.
There's also the category "child_alone" which is never addressed by any row.
This may cause problems during ML. So this column gets dropped during ML.

## ML-Pipeline

The script for running the ML-Pipeline is called "workplace/model/train_classifier.py".
It takes two arguments:
  * the sqlite file generated by the ETL-Pipeline
  * the name where to save the model

I tried several different classifiers. The best prediction I got was by SVC.
Because this classifiers can't handle single-value targets I removed the category
'child_alone'.

The script uses GridSearchCV to find the best parameters. Then it prints out a
classification report containing precission, recall and f1-score for each category.

Please note: I'm using a newer version of Scikit-learn than the one at Udacity.
So I don't have to loop over the categories. Instead I can print the results in
one step.

Because I want to use more than one processor core I had to move

stop_words = stopwords.words('english')

out of the tokenize function.  (see code)

## Web-app

The flask web-app is located at "workplace/app/run.py".

It shows three plotly charts:
* The original Distribution of Message-Genres
* Distribution of categories
* A histogram showing the distribution of number of categories per message.
* When typing a new message into the input field it get's classified.

## Jupyter notebooks

There are two jupyter notebooks used to analyse the data and prepare the scripts
mentioned above.

## Libraries

The following python packages are used:
* pandas (0.24.2)
* sqlalchemy (1.3.7)
* ntlk (3.4.4)
* sklearn (0.20.3)
* matplotlib (3.0.3)
* seaborn (0.9.0)
