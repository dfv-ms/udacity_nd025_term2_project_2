{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/stingl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stingl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/stingl/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.externals import joblib\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# \n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///messages.db')\n",
    "connection = engine.connect()\n",
    "df = pd.read_sql_table(\"messages\", con=connection)\n",
    "X = df.iloc[:, 1]\n",
    "Y = df.iloc[:, 4:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize andremove stop words\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('mcfl', MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators = 10)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..._score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=None))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:  0, f1-score: 0.880, precision:  0.841, recall:  0.922\n",
      "Category:  1, f1-score: 0.583, precision:  0.794, recall:  0.461\n",
      "Category:  2, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category:  3, f1-score: 0.659, precision:  0.753, recall:  0.587\n",
      "Category:  4, f1-score: 0.152, precision:  0.696, recall:  0.085\n",
      "Category:  5, f1-score: 0.243, precision:  0.759, recall:  0.145\n",
      "Category:  6, f1-score: 0.128, precision:  0.630, recall:  0.071\n",
      "Category:  7, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category:  8, f1-score: 0.154, precision:  0.719, recall:  0.086\n",
      "Caterogy:  9 doesn't have value 1\n",
      "Category: 10, f1-score: 0.464, precision:  0.866, recall:  0.316\n",
      "Category: 11, f1-score: 0.618, precision:  0.829, recall:  0.492\n",
      "Category: 12, f1-score: 0.436, precision:  0.810, recall:  0.298\n",
      "Category: 13, f1-score: 0.146, precision:  0.714, recall:  0.081\n",
      "Category: 14, f1-score: 0.070, precision:  0.875, recall:  0.036\n",
      "Category: 15, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 16, f1-score: 0.156, precision:  0.657, recall:  0.089\n",
      "Category: 17, f1-score: 0.268, precision:  0.709, recall:  0.165\n",
      "Category: 18, f1-score: 0.096, precision:  0.529, recall:  0.053\n",
      "Category: 19, f1-score: 0.018, precision:  0.217, recall:  0.010\n",
      "Category: 20, f1-score: 0.185, precision:  0.661, recall:  0.108\n",
      "Category: 21, f1-score: 0.229, precision:  0.694, recall:  0.137\n",
      "Category: 22, f1-score: 0.089, precision:  0.700, recall:  0.047\n",
      "Category: 23, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 24, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 25, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 26, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 27, f1-score: 0.017, precision:  0.300, recall:  0.009\n",
      "Category: 28, f1-score: 0.704, precision:  0.846, recall:  0.602\n",
      "Category: 29, f1-score: 0.536, precision:  0.864, recall:  0.388\n",
      "Category: 30, f1-score: 0.481, precision:  0.791, recall:  0.345\n",
      "Category: 31, f1-score: 0.265, precision:  0.600, recall:  0.170\n",
      "Category: 32, f1-score: 0.731, precision:  0.864, recall:  0.634\n",
      "Category: 33, f1-score: 0.158, precision:  0.714, recall:  0.089\n",
      "Category: 34, f1-score: 0.054, precision:  0.550, recall:  0.028\n",
      "Category: 35, f1-score: 0.453, precision:  0.729, recall:  0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def show_metrics(Y_test, Y_pred):\n",
    "    \"\"\"\n",
    "    Print f1-score, precision and recall for each category\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y_test: True values,\n",
    "    Y_pred: Predicted values\n",
    "    \"\"\"\n",
    "    for cat in range(0, Y_test.shape[1]):\n",
    "        cf=classification_report(Y_test.iloc[:, cat], pd.DataFrame(Y_pred).iloc[:, cat], output_dict=True).get('1')\n",
    "        if cf is not None:\n",
    "            print(f\"Category:{cat: 3d}, f1-score: {cf['f1-score'] :5.3f}, precision: {cf['precision']: 5.3f}, recall: {cf['recall']: 5.3f}\")\n",
    "        else:\n",
    "            print(f\"Caterogy:{cat: 3d} doesn't have value 1\")\n",
    "                  \n",
    "Y_pred = pipeline.predict(X_test)                  \n",
    "show_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88      5941\n",
      "           1       0.79      0.46      0.58      1333\n",
      "           2       0.00      0.00      0.00        34\n",
      "           3       0.75      0.59      0.66      3286\n",
      "           4       0.70      0.09      0.15       644\n",
      "           5       0.76      0.14      0.24       414\n",
      "           6       0.63      0.07      0.13       239\n",
      "           7       0.00      0.00      0.00       156\n",
      "           8       0.72      0.09      0.15       267\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.87      0.32      0.46       512\n",
      "          11       0.83      0.49      0.62       878\n",
      "          12       0.81      0.30      0.44       714\n",
      "          13       0.71      0.08      0.15       123\n",
      "          14       0.88      0.04      0.07       192\n",
      "          15       0.00      0.00      0.00        88\n",
      "          16       0.66      0.09      0.16       259\n",
      "          17       0.71      0.17      0.27       369\n",
      "          18       0.53      0.05      0.10      1021\n",
      "          19       0.22      0.01      0.02       521\n",
      "          20       0.66      0.11      0.19       362\n",
      "          21       0.69      0.14      0.23       430\n",
      "          22       0.70      0.05      0.09       148\n",
      "          23       0.00      0.00      0.00        46\n",
      "          24       0.00      0.00      0.00        90\n",
      "          25       0.00      0.00      0.00        39\n",
      "          26       0.00      0.00      0.00        86\n",
      "          27       0.30      0.01      0.02       350\n",
      "          28       0.85      0.60      0.70      2188\n",
      "          29       0.86      0.39      0.54       639\n",
      "          30       0.79      0.35      0.48       744\n",
      "          31       0.60      0.17      0.27        88\n",
      "          32       0.86      0.63      0.73       734\n",
      "          33       0.71      0.09      0.16       169\n",
      "          34       0.55      0.03      0.05       388\n",
      "          35       0.73      0.33      0.45      1547\n",
      "\n",
      "   micro avg       0.81      0.48      0.60     25039\n",
      "   macro avg       0.55      0.19      0.25     25039\n",
      "weighted avg       0.74      0.48      0.54     25039\n",
      " samples avg       0.65      0.44      0.48     25039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x1a1bf09d40>, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('mcfl',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "               oob_score=False, random_state=None, verbose=0,\n",
       "               warm_start=False),\n",
       "              n_jobs=None))],\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x1a1bf09d40>, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'mcfl': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_jobs=None),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'mcfl__estimator__bootstrap': True,\n",
       " 'mcfl__estimator__class_weight': None,\n",
       " 'mcfl__estimator__criterion': 'gini',\n",
       " 'mcfl__estimator__max_depth': None,\n",
       " 'mcfl__estimator__max_features': 'auto',\n",
       " 'mcfl__estimator__max_leaf_nodes': None,\n",
       " 'mcfl__estimator__min_impurity_decrease': 0.0,\n",
       " 'mcfl__estimator__min_impurity_split': None,\n",
       " 'mcfl__estimator__min_samples_leaf': 1,\n",
       " 'mcfl__estimator__min_samples_split': 2,\n",
       " 'mcfl__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'mcfl__estimator__n_estimators': 10,\n",
       " 'mcfl__estimator__n_jobs': None,\n",
       " 'mcfl__estimator__oob_score': False,\n",
       " 'mcfl__estimator__random_state': None,\n",
       " 'mcfl__estimator__verbose': 0,\n",
       " 'mcfl__estimator__warm_start': False,\n",
       " 'mcfl__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'mcfl__n_jobs': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=12)]: Done  67 out of  81 | elapsed:  7.4min remaining:  1.6min\n",
      "[Parallel(n_jobs=12)]: Done  76 out of  81 | elapsed:  8.4min remaining:   33.3s\n",
      "[Parallel(n_jobs=12)]: Done  81 out of  81 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..._score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=12,\n",
       "       param_grid={'mcfl__estimator__max_depth': [20, 50, 100], 'mcfl__estimator__min_samples_split': [2, 5, 20], 'mcfl__estimator__n_estimators': [5, 10, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "#     'vect__binary': [True, False], \n",
    "    'mcfl__estimator__max_depth': [20, 50, 100],\n",
    "    'mcfl__estimator__min_samples_split': [2, 5, 20],\n",
    "    'mcfl__estimator__n_estimators': [5, 10, 20]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=10, cv=3, n_jobs=12, scoring='f1_micro')\n",
    "\n",
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcfl__estimator__max_depth': 100,\n",
       " 'mcfl__estimator__min_samples_split': 20,\n",
       " 'mcfl__estimator__n_estimators': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6015905887601704"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758748994368463"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:  0, f1-score: 0.878, precision:  0.802, recall:  0.969\n",
      "Category:  1, f1-score: 0.512, precision:  0.758, recall:  0.386\n",
      "Category:  2, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category:  3, f1-score: 0.650, precision:  0.731, recall:  0.586\n",
      "Category:  4, f1-score: 0.228, precision:  0.621, recall:  0.140\n",
      "Category:  5, f1-score: 0.210, precision:  0.718, recall:  0.123\n",
      "Category:  6, f1-score: 0.049, precision:  0.857, recall:  0.025\n",
      "Category:  7, f1-score: 0.024, precision:  0.182, recall:  0.013\n",
      "Category:  8, f1-score: 0.181, precision:  0.547, recall:  0.109\n",
      "Caterogy:  9 doesn't have value 1\n",
      "Category: 10, f1-score: 0.379, precision:  0.850, recall:  0.244\n",
      "Category: 11, f1-score: 0.414, precision:  0.775, recall:  0.282\n",
      "Category: 12, f1-score: 0.462, precision:  0.738, recall:  0.336\n",
      "Category: 13, f1-score: 0.162, precision:  0.846, recall:  0.089\n",
      "Category: 14, f1-score: 0.049, precision:  0.357, recall:  0.026\n",
      "Category: 15, f1-score: 0.158, precision:  0.615, recall:  0.091\n",
      "Category: 16, f1-score: 0.139, precision:  0.714, recall:  0.077\n",
      "Category: 17, f1-score: 0.305, precision:  0.732, recall:  0.192\n",
      "Category: 18, f1-score: 0.047, precision:  0.481, recall:  0.024\n",
      "Category: 19, f1-score: 0.037, precision:  0.435, recall:  0.019\n",
      "Category: 20, f1-score: 0.098, precision:  0.704, recall:  0.052\n",
      "Category: 21, f1-score: 0.148, precision:  0.795, recall:  0.081\n",
      "Category: 22, f1-score: 0.098, precision:  0.500, recall:  0.054\n",
      "Category: 23, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 24, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 25, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 26, f1-score: 0.000, precision:  0.000, recall:  0.000\n",
      "Category: 27, f1-score: 0.017, precision:  0.333, recall:  0.009\n",
      "Category: 28, f1-score: 0.640, precision:  0.817, recall:  0.526\n",
      "Category: 29, f1-score: 0.286, precision:  0.743, recall:  0.177\n",
      "Category: 30, f1-score: 0.437, precision:  0.760, recall:  0.306\n",
      "Category: 31, f1-score: 0.022, precision:  0.250, recall:  0.011\n",
      "Category: 32, f1-score: 0.506, precision:  0.859, recall:  0.358\n",
      "Category: 33, f1-score: 0.209, precision:  0.909, recall:  0.118\n",
      "Category: 34, f1-score: 0.073, precision:  0.652, recall:  0.039\n",
      "Category: 35, f1-score: 0.426, precision:  0.750, recall:  0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y_pred = cv.predict(X_test)\n",
    "\n",
    "show_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88      5941\n",
      "           1       0.76      0.39      0.51      1333\n",
      "           2       0.00      0.00      0.00        34\n",
      "           3       0.73      0.59      0.65      3286\n",
      "           4       0.62      0.14      0.23       644\n",
      "           5       0.72      0.12      0.21       414\n",
      "           6       0.86      0.03      0.05       239\n",
      "           7       0.18      0.01      0.02       156\n",
      "           8       0.55      0.11      0.18       267\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.85      0.24      0.38       512\n",
      "          11       0.78      0.28      0.41       878\n",
      "          12       0.74      0.34      0.46       714\n",
      "          13       0.85      0.09      0.16       123\n",
      "          14       0.36      0.03      0.05       192\n",
      "          15       0.62      0.09      0.16        88\n",
      "          16       0.71      0.08      0.14       259\n",
      "          17       0.73      0.19      0.30       369\n",
      "          18       0.48      0.02      0.05      1021\n",
      "          19       0.43      0.02      0.04       521\n",
      "          20       0.70      0.05      0.10       362\n",
      "          21       0.80      0.08      0.15       430\n",
      "          22       0.50      0.05      0.10       148\n",
      "          23       0.00      0.00      0.00        46\n",
      "          24       0.00      0.00      0.00        90\n",
      "          25       0.00      0.00      0.00        39\n",
      "          26       0.00      0.00      0.00        86\n",
      "          27       0.33      0.01      0.02       350\n",
      "          28       0.82      0.53      0.64      2188\n",
      "          29       0.74      0.18      0.29       639\n",
      "          30       0.76      0.31      0.44       744\n",
      "          31       0.25      0.01      0.02        88\n",
      "          32       0.86      0.36      0.51       734\n",
      "          33       0.91      0.12      0.21       169\n",
      "          34       0.65      0.04      0.07       388\n",
      "          35       0.75      0.30      0.43      1547\n",
      "\n",
      "   micro avg       0.78      0.46      0.58     25039\n",
      "   macro avg       0.55      0.16      0.22     25039\n",
      "weighted avg       0.72      0.46      0.50     25039\n",
      " samples avg       0.67      0.44      0.48     25039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns with only 1 value\n",
    "\"child_alone\" and maybe other columns have only one value. So drop them because they may cause problems with some Classificators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_single_value_columns(data):\n",
    "    \"\"\"\n",
    "    Drop any column which doesn't contain two diffent values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data: DataFrame\n",
    "    \n",
    "    Return value:\n",
    "    -------------\n",
    "    DataFrame with column(s) removed\n",
    "    \"\"\"\n",
    "    \n",
    "    data.columns[data.nunique(axis=0) != 2]\n",
    "    data.drop(columns=data.columns[data.nunique(axis=0) != 2], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   3 out of   3 | elapsed:  8.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done   3 out of   3 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ity=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=12,\n",
       "       param_grid={'mcfl__estimator__kernel': ['linear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 1]\n",
    "Y = drop_single_value_columns(df.iloc[:, 4:]) \n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('mcfl', MultiOutputClassifier(estimator=SVC()))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "#     'mcfl__estimator__kernel' : ['linear', 'rbf', 'sigmoid'],\n",
    "    'mcfl__estimator__kernel' : ['linear'],\n",
    "#     'mcfl__estimator__degree' : [3, 4, 5, 6],\n",
    "#     'mcfl__estimator__kernel' : ['poly'],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=10, cv=3, n_jobs=12, scoring='f1_micro')\n",
    "\n",
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcfl__estimator__kernel': 'linear'}\n",
      "0.6772289922751838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      5941\n",
      "           1       0.78      0.58      0.67      1333\n",
      "           2       0.00      0.00      0.00        34\n",
      "           3       0.75      0.69      0.72      3286\n",
      "           4       0.65      0.20      0.31       644\n",
      "           5       0.75      0.26      0.39       414\n",
      "           6       0.79      0.13      0.22       239\n",
      "           7       0.00      0.00      0.00       156\n",
      "           8       0.68      0.25      0.37       267\n",
      "           9       0.75      0.66      0.70       512\n",
      "          10       0.79      0.76      0.78       878\n",
      "          11       0.80      0.55      0.65       714\n",
      "          12       0.76      0.45      0.56       123\n",
      "          13       0.81      0.13      0.22       192\n",
      "          14       0.57      0.18      0.28        88\n",
      "          15       0.62      0.19      0.29       259\n",
      "          16       0.78      0.44      0.56       369\n",
      "          17       0.58      0.09      0.15      1021\n",
      "          18       0.33      0.00      0.01       521\n",
      "          19       0.66      0.20      0.31       362\n",
      "          20       0.79      0.35      0.48       430\n",
      "          21       0.77      0.23      0.35       148\n",
      "          22       0.00      0.00      0.00        46\n",
      "          23       0.00      0.00      0.00        90\n",
      "          24       0.00      0.00      0.00        39\n",
      "          25       0.00      0.00      0.00        86\n",
      "          26       0.25      0.00      0.01       350\n",
      "          27       0.85      0.73      0.78      2188\n",
      "          28       0.91      0.56      0.70       639\n",
      "          29       0.76      0.65      0.70       744\n",
      "          30       0.68      0.26      0.38        88\n",
      "          31       0.89      0.80      0.84       734\n",
      "          32       0.71      0.28      0.40       169\n",
      "          33       0.77      0.08      0.14       388\n",
      "          34       0.73      0.47      0.57      1547\n",
      "\n",
      "   micro avg       0.81      0.59      0.68     25039\n",
      "   macro avg       0.60      0.32      0.38     25039\n",
      "weighted avg       0.76      0.59      0.63     25039\n",
      " samples avg       0.63      0.50      0.52     25039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y_pred = cv.predict(X_test)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)\n",
    "print(classification_report(Y_test, Y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1]\n",
    "Y = df.iloc[:, 4:].drop(columns='child_alone')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('mcfl', MultiOutputClassifier(estimator=SVC()))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "#     'mcfl__estimator__kernel' : ['linear', 'rbf', 'sigmoid'],\n",
    "    'mcfl__estimator__degree' : [2, 3, 4, 5, 6],\n",
    "    'mcfl__estimator__kernel' : ['poly'],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=10, cv=3, n_jobs=12, scoring='f1_micro')\n",
    "\n",
    "cv.fit(X_train, Y_train)\n",
    "Y_pred = cv.predict(X_test)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)\n",
    "print(classification_report(Y_test, Y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "X = df.iloc[:, 1]\n",
    "Y = df.iloc[:, 4:].drop(columns='child_alone')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('mcfl', MultiOutputClassifier(estimator=LinearSVC()))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'mcfl__estimator__C' : [1],\n",
    "    'mcfl__estimator__loss' : ['hinge', 'squared_hinge'],\n",
    "    'mcfl__estimator__max_iter' : [1000, 10000]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=10, cv=3, n_jobs=12, scoring='f1_micro')\n",
    "\n",
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = cv.predict(X_test)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  12 | elapsed:   30.5s remaining:  1.5min\n",
      "[Parallel(n_jobs=12)]: Done   5 out of  12 | elapsed:   30.6s remaining:   42.8s\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  12 | elapsed:   30.7s remaining:   21.9s\n",
      "[Parallel(n_jobs=12)]: Done   9 out of  12 | elapsed:   30.8s remaining:   10.3s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   33.5s finished\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/naive_bayes.py:465: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...fier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=12,\n",
       "       param_grid={'mcfl__estimator__alpha': [0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X = df.iloc[:, 1]\n",
    "Y = df.iloc[:, 4:] #.drop(columns='child_alone')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('mcfl', MultiOutputClassifier(estimator=MultinomialNB()))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'mcfl__estimator__alpha' : [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=10, cv=3, n_jobs=12, scoring='f1_micro')\n",
    "\n",
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcfl__estimator__alpha': 0.01}\n",
      "0.587659155515815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      5941\n",
      "           1       0.67      0.59      0.63      1333\n",
      "           2       0.00      0.00      0.00        34\n",
      "           3       0.67      0.66      0.66      3286\n",
      "           4       0.54      0.21      0.30       644\n",
      "           5       0.49      0.22      0.30       414\n",
      "           6       0.58      0.06      0.11       239\n",
      "           7       0.17      0.01      0.02       156\n",
      "           8       0.55      0.30      0.39       267\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.51      0.20      0.28       512\n",
      "          11       0.61      0.37      0.46       878\n",
      "          12       0.59      0.27      0.37       714\n",
      "          13       0.48      0.24      0.32       123\n",
      "          14       0.51      0.10      0.17       192\n",
      "          15       0.25      0.02      0.04        88\n",
      "          16       0.23      0.04      0.07       259\n",
      "          17       0.60      0.22      0.32       369\n",
      "          18       0.26      0.05      0.08      1021\n",
      "          19       0.24      0.06      0.09       521\n",
      "          20       0.52      0.14      0.22       362\n",
      "          21       0.56      0.16      0.25       430\n",
      "          22       0.44      0.09      0.16       148\n",
      "          23       0.00      0.00      0.00        46\n",
      "          24       0.40      0.02      0.04        90\n",
      "          25       0.00      0.00      0.00        39\n",
      "          26       0.11      0.01      0.02        86\n",
      "          27       0.24      0.05      0.08       350\n",
      "          28       0.70      0.60      0.65      2188\n",
      "          29       0.60      0.38      0.46       639\n",
      "          30       0.63      0.41      0.50       744\n",
      "          31       0.50      0.10      0.17        88\n",
      "          32       0.79      0.44      0.57       734\n",
      "          33       0.59      0.16      0.25       169\n",
      "          34       0.24      0.05      0.09       388\n",
      "          35       0.63      0.50      0.56      1547\n",
      "\n",
      "   micro avg       0.70      0.51      0.59     25039\n",
      "   macro avg       0.44      0.21      0.26     25039\n",
      "weighted avg       0.63      0.51      0.54     25039\n",
      " samples avg       0.61      0.47      0.47     25039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/stingl/anaconda3/envs/nd025_aktuell/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y_pred = cv.predict(X_test)\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, 'classifier.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  26  27  28  29  30  31  32  \\\n",
       "0   1   0   0   1   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1   1   0   0   0   0   0   0   0   0   0  ...   0   0   1   0   1   0   0   \n",
       "2   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
       "4   1   0   0   1   0   0   0   0   0   0  ...   0   0   1   0   1   0   1   \n",
       "\n",
       "   33  34  35  \n",
       "0   0   0   0  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = joblib.load('classifier.pkl')\n",
    "pd.DataFrame(cls.predict(X_test)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
